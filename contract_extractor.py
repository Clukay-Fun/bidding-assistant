"""
åˆåŒä¿¡æ¯æå–æ¨¡å—
åŠŸèƒ½ï¼š
1. PDF â†’ å›¾ç‰‡ï¼ˆä¿å­˜ä¸ºBLOBï¼‰
2. OCRè¯†åˆ«æ–‡æœ¬ï¼ˆåˆæ­¥ï¼‰
3. GLM-4.1Vè§†è§‰æ ¡éªŒ + ç»“æ„åŒ–æå–ï¼ˆç²¾å‡†ï¼‰
4. å­˜å…¥æ•°æ®åº“
"""

from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI
from pdf2image import convert_from_path
from PIL import Image
import json
import os
import io
import base64
import time

from database import get_session, add_contract, Contract
from text_cleaner import filter_watermarks

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ============================================
# region é…ç½®åŒºåŸŸ
# ============================================

# Popplerè·¯å¾„
POPPLER_PATH = r"D:\.Software\poppler\Library\bin"

# ç¡…åŸºæµåŠ¨APIé…ç½®
SILICONFLOW_API_KEY = os.getenv("SILICONFLOW_API_KEY")
SILICONFLOW_BASE_URL = "https://api.siliconflow.cn/v1"

# æ¨¡å‹é…ç½®
VISION_MODEL = "THUDM/GLM-4.1V-9B-Thinking"  # è§†è§‰æ¨¡å‹ï¼ˆæ ¡éªŒ+æå–ï¼‰
EXTRACT_MODEL = "Qwen/Qwen3-8B"  # å¤‡ç”¨æ–‡æœ¬æ¨¡å‹

# è¾“å‡ºç›®å½•
OUTPUT_DIR = Path("./output")
OUTPUT_DIR.mkdir(exist_ok=True)

# endregion
# ============================================

# ============================================
# region æ•°æ®æ¸…æ´—
# ============================================

def clean_float(value):
    """æ¸…æ´—æµ®ç‚¹æ•°å­—æ®µ"""
    if value is None or value == "" or value == "null":
        return None
    try:
        return float(value)
    except (ValueError, TypeError):
        return None


def clean_bool(value):
    """æ¸…æ´—å¸ƒå°”å­—æ®µ"""
    if value is None:
        return False
    if isinstance(value, bool):
        return value
    if isinstance(value, str):
        return value.lower() in ['true', 'yes', 'æ˜¯', '1']
    return bool(value)


def clean_string(value):
    """æ¸…æ´—å­—ç¬¦ä¸²å­—æ®µ"""
    if value is None or value == "null":
        return None
    return str(value).strip() if value else None

# endregion
# ============================================

# ============================================
# region PDFå¤„ç†
# ============================================

def pdf_to_images(pdf_path: str, dpi: int = 200) -> list:
    """å°†PDFè½¬æ¢ä¸ºå›¾ç‰‡åˆ—è¡¨"""
    print(f"ğŸ“„ æ­£åœ¨å°†PDFè½¬ä¸ºå›¾ç‰‡: {pdf_path}")
    
    images = convert_from_path(
        pdf_path,
        poppler_path=POPPLER_PATH,
        dpi=dpi
    )
    
    print(f"   âœ… å…±è½¬æ¢ {len(images)} é¡µ")
    return images


def images_to_blob(images: list) -> bytes:
    """å°†å¤šå¼ å›¾ç‰‡åˆå¹¶ä¸ºå•ä¸ªBLOBï¼ˆZIPæ ¼å¼ï¼‰"""
    import zipfile
    
    buffer = io.BytesIO()
    
    with zipfile.ZipFile(buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
        for i, img in enumerate(images):
            img_buffer = io.BytesIO()
            img.save(img_buffer, format='PNG')
            zf.writestr(f"page_{i+1}.png", img_buffer.getvalue())
    
    return buffer.getvalue()


def blob_to_images(blob_data: bytes) -> list:
    """ä»BLOBè§£å‹å›¾ç‰‡"""
    import zipfile
    
    images = []
    buffer = io.BytesIO(blob_data)
    
    with zipfile.ZipFile(buffer, 'r') as zf:
        for name in sorted(zf.namelist()):
            img_data = zf.read(name)
            img = Image.open(io.BytesIO(img_data))
            images.append(img)
    
    return images


def image_to_base64(image: Image.Image, max_size: int = 1024) -> str:
    """å°†å›¾ç‰‡è½¬æ¢ä¸ºbase64ï¼ˆå‹ç¼©ä»¥èŠ‚çœtokenï¼‰"""
    # è°ƒæ•´å¤§å°
    if max(image.size) > max_size:
        ratio = max_size / max(image.size)
        new_size = (int(image.size[0] * ratio), int(image.size[1] * ratio))
        image = image.resize(new_size, Image.Resampling.LANCZOS)
    
    # è½¬æ¢ä¸ºbase64
    buffer = io.BytesIO()
    image.save(buffer, format='JPEG', quality=85)
    return base64.b64encode(buffer.getvalue()).decode('utf-8')

# endregion
# ============================================


# ============================================
# region OCRè¯†åˆ«ï¼ˆåˆæ­¥ï¼‰
# ============================================

def ocr_images(images: list) -> str:
    """å¯¹å›¾ç‰‡è¿›è¡ŒOCRè¯†åˆ«ï¼Œè¿”å›åˆå¹¶çš„æ–‡æœ¬"""
    from paddleocr import PaddleOCR
    
    print("ğŸ”§ æ­£åœ¨è¿›è¡ŒOCRè¯†åˆ«ï¼ˆåˆæ­¥ï¼‰...")
    
    ocr = PaddleOCR(
        lang='ch',
        use_doc_orientation_classify=False,
        use_doc_unwarping=False,
        use_textline_orientation=False,
    )
    
    all_results = []
    
    for i, image in enumerate(images):
        print(f"   ğŸ” è¯†åˆ«ç¬¬ {i+1}/{len(images)} é¡µ...")
        
        temp_path = OUTPUT_DIR / f"temp_page_{i+1}.png"
        image.save(temp_path)
        
        result = ocr.predict(str(temp_path))
        
        page_text = []
        if result:
            for item in result:
                if isinstance(item, dict):
                    rec_texts = item.get('rec_texts', [])
                    for text in rec_texts:
                        page_text.append(text)
        
        all_results.append({
            "page": i + 1,
            "content": [{"text": t, "confidence": 0.9} for t in page_text]
        })
        
        temp_path.unlink(missing_ok=True)
    
    # è¿‡æ»¤æ°´å°
    print("   ğŸ” è¿‡æ»¤æ°´å°...")
    filtered_results = filter_watermarks(all_results)
    
    # åˆå¹¶æ–‡æœ¬
    full_text = ""
    for page in filtered_results:
        full_text += f"\n--- ç¬¬{page['page']}é¡µ ---\n"
        for item in page['content']:
            full_text += item['text'] + "\n"
    
    print(f"   âœ… OCRå®Œæˆï¼Œå…±æå– {len(full_text)} å­—ç¬¦")
    return full_text

# endregion
# ============================================


# ============================================
# region GLM-4.1V è§†è§‰æå–
# ============================================

VISION_EXTRACT_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ³•å¾‹åˆåŒä¿¡æ¯æå–ä¸“å®¶ã€‚æˆ‘ä¼šç»™ä½ åˆåŒçš„æ‰«æå›¾ç‰‡ï¼Œè¯·ä»”ç»†æŸ¥çœ‹å›¾ç‰‡å†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯ã€‚

## é‡è¦æç¤º
- è¯·ç›´æ¥ä»å›¾ç‰‡ä¸­è¯†åˆ«æ–‡å­—ï¼Œä¸è¦ä¾èµ–OCRå‚è€ƒæ–‡æœ¬ä¸­çš„é”™è¯¯
- äººåã€å…¬å¸åè¦å®Œæ•´å‡†ç¡®ï¼Œä¸è¦æ¼å­—
- ä»”ç»†è¾¨è®¤æ¯ä¸€ä¸ªæ±‰å­—

## æå–å­—æ®µ

1. **contract_name**: åˆåŒåç§°/æ ‡é¢˜
2. **party_a**: ç”²æ–¹åç§°ï¼ˆå§”æ‰˜æ–¹ï¼‰- è¯·å®Œæ•´å‡†ç¡®è¯†åˆ«
3. **party_a_id**: ç”²æ–¹èº«ä»½è¯å·æˆ–ç»Ÿä¸€ç¤¾ä¼šä¿¡ç”¨ä»£ç 
4. **party_a_industry**: ç”²æ–¹æ‰€åœ¨è¡Œä¸šï¼ˆå¦‚ï¼šç‡ƒæ°”ã€é“¶è¡Œã€åŒ»ç–—ã€ä¸ªäººç­‰ï¼‰
5. **is_state_owned**: æ˜¯å¦æ˜¯å›½ä¼ï¼ˆtrue/falseï¼‰
6. **is_individual**: æ˜¯å¦æ˜¯ä¸ªäººï¼ˆtrue/falseï¼‰
7. **amount**: åˆåŒé‡‘é¢ï¼ˆæ•°å­—ï¼Œå•ä½ï¼šä¸‡å…ƒï¼‰
8. **fee_method**: æ”¶è´¹æ–¹å¼
9. **sign_date**: ç­¾è®¢æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰
10. **project_type**: é¡¹ç›®ç±»å‹ï¼ˆåªèƒ½å¡«ï¼šå¸¸æ³•/è¯‰è®¼/ä¸“é¡¹ï¼‰
11. **project_detail**: é¡¹ç›®è¯¦æƒ…/æœåŠ¡å†…å®¹/æ¡ˆä»¶åç§°
12. **subject_amount**: æ ‡çš„é¢ï¼ˆè¯‰è®¼é¡¹ç›®ï¼Œå•ä½ï¼šä¸‡å…ƒï¼‰
13. **opponent**: å¯¹æ–¹å½“äº‹äººï¼ˆè¯‰è®¼é¡¹ç›®ï¼‰
14. **team_member**: å›¢é˜Ÿæˆå‘˜/æ‰¿åŠå¾‹å¸ˆ - è¯·å®Œæ•´å‡†ç¡®è¯†åˆ«æ¯ä¸ªäººçš„å§“å
15. **summary**: ä¸€å¥è¯æ¦‚æ‹¬åˆåŒæ ¸å¿ƒå†…å®¹ï¼ˆ50å­—ä»¥å†…ï¼‰

## OCRå‚è€ƒæ–‡æœ¬ï¼ˆå¯èƒ½æœ‰é”™è¯¯ï¼Œä»…ä¾›å‚è€ƒï¼‰

{ocr_text}

## è¾“å‡ºæ ¼å¼

è¯·ç›´æ¥è¾“å‡ºJSONï¼Œä¸è¦åŒ…å«```json```æ ‡è®°ï¼š
{{
  "contract_name": "...",
  "party_a": "...",
  "party_a_id": "...",
  "party_a_industry": "...",
  "is_state_owned": false,
  "is_individual": false,
  "amount": 0,
  "fee_method": "...",
  "sign_date": "YYYY-MM-DD",
  "project_type": "å¸¸æ³•/è¯‰è®¼/ä¸“é¡¹",
  "project_detail": "...",
  "subject_amount": null,
  "opponent": null,
  "team_member": "...",
  "summary": "..."
}}
"""


def extract_with_vision(images: list, ocr_text: str, max_pages: int = 5) -> dict:
    """
    ä½¿ç”¨GLM-4.1Vè§†è§‰æ¨¡å‹æå–åˆåŒä¿¡æ¯
    
    å‚æ•°:
        images: å›¾ç‰‡åˆ—è¡¨
        ocr_text: OCRè¯†åˆ«çš„å‚è€ƒæ–‡æœ¬
        max_pages: æœ€å¤šå‘é€å‡ é¡µå›¾ç‰‡ï¼ˆæ§åˆ¶APIæ¶ˆè€—ï¼‰
    """
    print("ğŸ¤– GLM-4.1V è§†è§‰æå–ä¸­...")
    
    client = OpenAI(
        api_key=SILICONFLOW_API_KEY,
        base_url=SILICONFLOW_BASE_URL
    )
    
    # å‡†å¤‡å›¾ç‰‡ï¼ˆå–å‰å‡ é¡µï¼Œé€šå¸¸åˆåŒå…³é”®ä¿¡æ¯åœ¨å‰é¢ï¼‰
    selected_images = images[:max_pages]
    
    # æ„å»ºæ¶ˆæ¯å†…å®¹
    content = []
    
    # æ·»åŠ å›¾ç‰‡
    for i, img in enumerate(selected_images):
        img_base64 = image_to_base64(img)
        content.append({
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{img_base64}"
            }
        })
    
    # æ·»åŠ æ–‡æœ¬æç¤º
    prompt = VISION_EXTRACT_PROMPT.format(ocr_text=ocr_text[:3000])  # é™åˆ¶OCRæ–‡æœ¬é•¿åº¦
    content.append({
        "type": "text",
        "text": prompt
    })
    
    try:
        response = client.chat.completions.create(
            model=VISION_MODEL,
            messages=[
                {
                    "role": "user",
                    "content": content
                }
            ],
            temperature=0.1,
            max_tokens=2000
        )
        
        result_text = response.choices[0].message.content.strip()
        
        # æ¸…ç†å¯èƒ½çš„markdownæ ‡è®°å’Œæ€è€ƒè¿‡ç¨‹
        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0]
        elif "```" in result_text:
            result_text = result_text.split("```")[1].split("```")[0]
        
        # å°è¯•æ‰¾åˆ°JSONéƒ¨åˆ†
        if "{" in result_text:
            start = result_text.find("{")
            end = result_text.rfind("}") + 1
            result_text = result_text[start:end]
        
        info = json.loads(result_text.strip())
        print("   âœ… è§†è§‰æå–å®Œæˆ")
        return info
        
    except json.JSONDecodeError as e:
        print(f"   âš ï¸ JSONè§£æå¤±è´¥: {e}")
        print(f"   åŸå§‹è¾“å‡º: {result_text[:500]}...")
        return {}
    except Exception as e:
        print(f"   âŒ è§†è§‰æå–å¤±è´¥: {e}")
        return {}

# endregion
# ============================================

# ============================================
# region ç¼“å­˜åŠŸèƒ½
# ============================================

import hashlib

CACHE_DIR = Path("./cache")
CACHE_DIR.mkdir(exist_ok=True)


def get_file_hash(file_path: str) -> str:
    """è®¡ç®—æ–‡ä»¶çš„MD5å“ˆå¸Œ"""
    hasher = hashlib.md5()
    with open(file_path, 'rb') as f:
        for chunk in iter(lambda: f.read(8192), b''):
            hasher.update(chunk)
    return hasher.hexdigest()


def get_cache_path(file_path: str, cache_type: str) -> Path:
    """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
    file_hash = get_file_hash(file_path)
    return CACHE_DIR / f"{file_hash}_{cache_type}.json"


def load_cache(file_path: str, cache_type: str):
    """åŠ è½½ç¼“å­˜"""
    cache_path = get_cache_path(file_path, cache_type)
    if cache_path.exists():
        with open(cache_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return None


def save_cache(file_path: str, cache_type: str, data):
    """ä¿å­˜ç¼“å­˜"""
    cache_path = get_cache_path(file_path, cache_type)
    with open(cache_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# endregion
# ============================================

# ============================================
# region å¤‡ç”¨ï¼šçº¯æ–‡æœ¬æå–
# ============================================

EXTRACT_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ³•å¾‹åˆåŒä¿¡æ¯æå–ä¸“å®¶ã€‚è¯·ä»ä»¥ä¸‹åˆåŒæ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯ã€‚

## æå–å­—æ®µ

1. **contract_name**: åˆåŒåç§°
2. **party_a**: ç”²æ–¹åç§°
3. **party_a_id**: ç”²æ–¹èº«ä»½è¯/ç»Ÿä¸€ç¤¾ä¼šä¿¡ç”¨ä»£ç 
4. **party_a_industry**: ç”²æ–¹æ‰€åœ¨è¡Œä¸š
5. **is_state_owned**: æ˜¯å¦å›½ä¼ï¼ˆtrue/falseï¼‰
6. **is_individual**: æ˜¯å¦ä¸ªäººï¼ˆtrue/falseï¼‰
7. **amount**: åˆåŒé‡‘é¢ï¼ˆä¸‡å…ƒï¼‰
8. **fee_method**: æ”¶è´¹æ–¹å¼
9. **sign_date**: ç­¾è®¢æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
10. **project_type**: é¡¹ç›®ç±»å‹ï¼ˆå¸¸æ³•/è¯‰è®¼/ä¸“é¡¹ï¼‰
11. **project_detail**: é¡¹ç›®è¯¦æƒ…
12. **subject_amount**: æ ‡çš„é¢ï¼ˆè¯‰è®¼é¡¹ç›®ï¼Œä¸‡å…ƒï¼‰
13. **opponent**: å¯¹æ–¹å½“äº‹äººï¼ˆè¯‰è®¼é¡¹ç›®ï¼‰
14. **team_member**: å›¢é˜Ÿæˆå‘˜
15. **summary**: ä¸€å¥è¯æ¦‚æ‹¬ï¼ˆ50å­—å†…ï¼‰

## è¾“å‡ºJSONæ ¼å¼ï¼ˆä¸è¦```æ ‡è®°ï¼‰

## åˆåŒæ–‡æœ¬

"""


def extract_with_text(text: str) -> dict:
    """å¤‡ç”¨ï¼šä½¿ç”¨çº¯æ–‡æœ¬æ¨¡å‹æå–ï¼ˆä¸æ¶ˆè€—è§†è§‰APIï¼‰"""
    print("ğŸ¤– æ–‡æœ¬æ¨¡å‹æå–ä¸­ï¼ˆå¤‡ç”¨ï¼‰...")
    
    client = OpenAI(
        api_key=SILICONFLOW_API_KEY,
        base_url=SILICONFLOW_BASE_URL
    )
    
    try:
        response = client.chat.completions.create(
            model=EXTRACT_MODEL,
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸“ä¸šçš„æ³•å¾‹åˆåŒä¿¡æ¯æå–ä¸“å®¶ã€‚è¯·ä¸¥æ ¼æŒ‰JSONæ ¼å¼è¾“å‡ºã€‚"
                },
                {
                    "role": "user",
                    "content": EXTRACT_PROMPT + text[:8000]
                }
            ],
            temperature=0.1,
            max_tokens=2000
        )
        
        result_text = response.choices[0].message.content.strip()
        
        if result_text.startswith("```"):
            result_text = result_text.split("```")[1]
            if result_text.startswith("json"):
                result_text = result_text[4:]
        if result_text.endswith("```"):
            result_text = result_text[:-3]
        
        return json.loads(result_text.strip())
        
    except Exception as e:
        print(f"   âŒ æ–‡æœ¬æå–å¤±è´¥: {e}")
        return {}

# endregion
# ============================================


# ============================================
# region ä¸»å¤„ç†æµç¨‹
# ============================================

def process_contract_pdf(
    pdf_path: str, 
    save_to_db: bool = True,
    use_vision: bool = True,
    use_cache: bool = True
) -> dict:
    """
    å¤„ç†å•ä¸ªåˆåŒPDF
    
    å‚æ•°:
        pdf_path: PDFæ–‡ä»¶è·¯å¾„
        save_to_db: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“
        use_vision: æ˜¯å¦ä½¿ç”¨è§†è§‰æ¨¡å‹
        use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
    """
    start_time = time.time()
    
    print("\n" + "="*50)
    print(f"ğŸ“„ å¤„ç†åˆåŒ: {pdf_path}")
    print("="*50)
    
    file_name = Path(pdf_path).name
    
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´ç¼“å­˜
    if use_cache:
        cached_result = load_cache(pdf_path, "result")
        if cached_result:
            print("   ğŸ“¦ ä½¿ç”¨ç¼“å­˜ç»“æœ")
            return cached_result
    
    # 1. PDFè½¬å›¾ç‰‡ï¼ˆæ£€æŸ¥ç¼“å­˜ï¼‰
    images = None
    image_blob = None
    
    if use_cache:
        cached_images = load_cache(pdf_path, "images_meta")
        if cached_images:
            print("   ğŸ“¦ ä½¿ç”¨ç¼“å­˜å›¾ç‰‡ä¿¡æ¯")
            # é‡æ–°è½¬æ¢å›¾ç‰‡ï¼ˆå› ä¸ºå›¾ç‰‡å¯¹è±¡ä¸èƒ½ç¼“å­˜ï¼‰
            images = pdf_to_images(pdf_path)
            image_blob = images_to_blob(images)
        
    if images is None:
        images = pdf_to_images(pdf_path)
        print("ğŸ’¾ å‹ç¼©å›¾ç‰‡ä¸ºBLOB...")
        image_blob = images_to_blob(images)
        print(f"   âœ… BLOBå¤§å°: {len(image_blob) / 1024 / 1024:.2f} MB")
        
        if use_cache:
            save_cache(pdf_path, "images_meta", {"page_count": len(images)})
    
    # 2. OCRè¯†åˆ«ï¼ˆæ£€æŸ¥ç¼“å­˜ï¼‰
    raw_text = None
    
    if use_cache:
        cached_ocr = load_cache(pdf_path, "ocr")
        if cached_ocr:
            print("   ğŸ“¦ ä½¿ç”¨ç¼“å­˜OCRç»“æœ")
            raw_text = cached_ocr.get("text", "")
    
    if raw_text is None:
        raw_text = ocr_images(images)
        if use_cache:
            save_cache(pdf_path, "ocr", {"text": raw_text})
    
    # 3. AIæå–ä¿¡æ¯
    if use_vision:
        info = extract_with_vision(images, raw_text)
    else:
        info = extract_with_text(raw_text)
    
    # å¦‚æœè§†è§‰æå–å¤±è´¥ï¼Œå›é€€åˆ°æ–‡æœ¬æå–
    if not info and use_vision:
        print("   âš ï¸ è§†è§‰æå–å¤±è´¥ï¼Œå°è¯•æ–‡æœ¬æå–...")
        info = extract_with_text(raw_text)
    
    # 4. ä¿å­˜åˆ°æ•°æ®åº“
    if save_to_db and info:
        print("ğŸ’¾ ä¿å­˜åˆ°æ•°æ®åº“...")
        
        session = get_session()
        try:
            contract = add_contract(
                session,
                file_name=file_name,
                contract_name=clean_string(info.get("contract_name")),
                party_a=clean_string(info.get("party_a")),
                party_a_id=clean_string(info.get("party_a_id")),
                party_a_industry=clean_string(info.get("party_a_industry")),
                is_state_owned=clean_bool(info.get("is_state_owned")),
                is_individual=clean_bool(info.get("is_individual")),
                amount=clean_float(info.get("amount")),
                fee_method=clean_string(info.get("fee_method")),
                sign_date=clean_string(info.get("sign_date")),
                project_type=clean_string(info.get("project_type")),
                project_detail=clean_string(info.get("project_detail")),
                subject_amount=clean_float(info.get("subject_amount")),
                opponent=clean_string(info.get("opponent")),
                team_member=clean_string(info.get("team_member")),
                summary=clean_string(info.get("summary")),
                image_data=image_blob,
                image_count=len(images),
                raw_text=raw_text
            )
            print(f"   âœ… å·²ä¿å­˜ï¼ŒID: {contract.id}")
            info["db_id"] = contract.id
        except Exception as e:
            print(f"   âŒ ä¿å­˜å¤±è´¥: {e}")
        finally:
            session.close()
    
    # 5. ç¼“å­˜å®Œæ•´ç»“æœ
    if use_cache and info:
        save_cache(pdf_path, "result", info)
    
    elapsed = time.time() - start_time
    print(f"\nâ±ï¸ æ€»è€—æ—¶: {elapsed:.2f} ç§’")
    
    return info
# endregion
# ============================================

# ============================================
# region æ‰¹é‡å¤„ç†
# ============================================

def batch_process_contracts(
    folder_path: str,
    use_vision: bool = True,
    use_cache: bool = True
) -> list:
    """
    æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰åˆåŒPDF
    
    å‚æ•°:
        folder_path: æ–‡ä»¶å¤¹è·¯å¾„
        use_vision: æ˜¯å¦ä½¿ç”¨è§†è§‰æ¨¡å‹
        use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
    
    è¿”å›:
        å¤„ç†ç»“æœåˆ—è¡¨
    """
    folder = Path(folder_path)
    pdf_files = list(folder.glob("*.pdf"))
    
    print("\n" + "="*50)
    print(f"ğŸ“‚ æ‰¹é‡å¤„ç†åˆåŒ")
    print("="*50)
    print(f"ğŸ“ æ–‡ä»¶å¤¹: {folder_path}")
    print(f"ğŸ“„ å‘ç° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
    print(f"ğŸ¤– ä½¿ç”¨è§†è§‰æ¨¡å‹: {'æ˜¯' if use_vision else 'å¦'}")
    print(f"ğŸ“¦ ä½¿ç”¨ç¼“å­˜: {'æ˜¯' if use_cache else 'å¦'}")
    
    results = []
    
    for i, pdf_file in enumerate(pdf_files, 1):
        print(f"\n{'='*50}")
        print(f"[{i}/{len(pdf_files)}] {pdf_file.name}")
        print("="*50)
        
        try:
            info = process_contract_pdf(
                str(pdf_file), 
                save_to_db=True,
                use_vision=use_vision,
                use_cache=use_cache
            )
            results.append({
                "file": str(pdf_file),
                "status": "success",
                "info": info
            })
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            results.append({
                "file": str(pdf_file),
                "status": "failed",
                "error": str(e)
            })
    
    # ç»Ÿè®¡ç»“æœ
    success = len([r for r in results if r["status"] == "success"])
    failed = len([r for r in results if r["status"] == "failed"])
    
    print("\n" + "="*50)
    print(f"ğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆ")
    print("="*50)
    print(f"   âœ… æˆåŠŸ: {success}")
    print(f"   âŒ å¤±è´¥: {failed}")
    print(f"   ğŸ“ æ€»è®¡: {len(pdf_files)}")
    
    return results

# endregion
# ============================================

# ============================================
# region æµ‹è¯•å…¥å£
# ============================================

if __name__ == "__main__":
    import sys
    
    # é»˜è®¤è·¯å¾„
    default_folder = "./documents/ä¸šç»©"
    
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        path = sys.argv[1]
    else:
        path = default_folder
    
    from pathlib import Path
    
    if Path(path).is_file():
        # å•ä¸ªæ–‡ä»¶
        info = process_contract_pdf(path, use_vision=True)
        
        print("\n" + "="*50)
        print("ğŸ“‹ æå–ç»“æœé¢„è§ˆ")
        print("="*50)
        for key, value in info.items():
            if key != "db_id":
                print(f"   {key}: {value}")
    
    elif Path(path).is_dir():
        # æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹
        results = batch_process_contracts(path, use_vision=False)
        
        # ä¿å­˜å¤„ç†æŠ¥å‘Š
        import json
        report_path = Path("./output/batch_report.json")
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ“„ å¤„ç†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    else:
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {path}")

# endregion
# ============================================