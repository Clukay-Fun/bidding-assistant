"""
Agent æ ¸å¿ƒå¾ªç¯
å®ç° Think â†’ Act â†’ Observe çš„è‡ªä¸»å¾ªç¯

ç±»æ¯”ï¼šå›¾ä¹¦é¦†çš„æ™ºèƒ½ç®¡ç†å‘˜
- æ¥æ”¶ç”¨æˆ·è¯·æ±‚
- æ€è€ƒå¦‚ä½•å¤„ç†
- è°ƒç”¨å„ç§æŠ€èƒ½ï¼ˆå·¥å…·ï¼‰
- è§‚å¯Ÿç»“æœå¹¶å†³å®šä¸‹ä¸€æ­¥
- æœ€ç»ˆç»™å‡ºç­”æ¡ˆ
"""

import json
import re
from typing import Optional, Generator
from openai import OpenAI

from app.config import (
    SILICONFLOW_API_KEY,
    SILICONFLOW_BASE_URL,
    REASONING_MODEL,
    AGENT_MAX_STEPS,
)
from app.agent.state import AgentState, AgentContext
from app.agent.prompts import build_system_prompt
from app.tools import tool_registry


# ============================================
# region LLM å®¢æˆ·ç«¯
# ============================================

def get_llm_client() -> OpenAI:
    """è·å– LLM å®¢æˆ·ç«¯"""
    return OpenAI(
        api_key=SILICONFLOW_API_KEY,
        base_url=SILICONFLOW_BASE_URL,
    )

# endregion
# ============================================


# ============================================
# region å“åº”è§£æ
# ============================================

def parse_agent_response(response_text: str) -> dict:
    """
    è§£æ Agent çš„ JSON å“åº”
    
    å‚æ•°:
        response_text: LLM è¿”å›çš„æ–‡æœ¬
    è¿”å›:
        è§£æåçš„å­—å…¸
    """
    clean_text = response_text.strip()
    
    # ç§»é™¤ <think>...</think> æ ‡ç­¾ï¼ˆæŸäº›æ¨¡å‹ä¼šè¾“å‡ºï¼‰
    think_match = re.search(r'<think>.*?</think>', clean_text, re.DOTALL)
    if think_match:
        clean_text = clean_text[think_match.end():].strip()
    
    # å°è¯•æå– JSON å—ï¼ˆ```json ... ```ï¼‰
    json_match = re.search(r'```json\s*(.*?)\s*```', clean_text, re.DOTALL)
    if json_match:
        json_str = json_match.group(1).strip()
    else:
        # å°è¯•æå– ``` ... ```
        code_match = re.search(r'```\s*(.*?)\s*```', clean_text, re.DOTALL)
        if code_match:
            json_str = code_match.group(1).strip()
        else:
            # å°è¯•ç›´æ¥æŸ¥æ‰¾å®Œæ•´çš„ JSON å¯¹è±¡ {...}
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª }
            start_idx = clean_text.find('{')
            end_idx = clean_text.rfind('}')
            
            if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
                json_str = clean_text[start_idx:end_idx + 1]
            else:
                # æ— æ³•æ‰¾åˆ° JSON
                return {
                    "thought": clean_text[:500] if clean_text else "æ— æ³•è§£æå“åº”",
                    "action": None,
                    "answer": None,
                }
    
    # ç›´æ¥è§£æ JSONï¼ˆä¸è¦æ›¿æ¢æ¢è¡Œç¬¦ï¼Œjson.loads å¯ä»¥å¤„ç†ï¼‰
    try:
        result = json.loads(json_str)
        return {
            "thought": result.get("thought", ""),
            "action": result.get("action"),
            "answer": result.get("answer"),
        }
    except json.JSONDecodeError as e:
        print(f"   âš ï¸ JSON è§£æå¤±è´¥: {e}")
        print(f"   âš ï¸ å°è¯•è§£æçš„å†…å®¹: {json_str[:200]}...")
        
        # è¿”å›åŸæ–‡ä½œä¸ºæ€è€ƒå†…å®¹
        return {
            "thought": clean_text[:500],
            "action": None,
            "answer": None,
        }

# endregion
# ============================================


# ============================================
# region Agent ç±»
# ============================================

class Agent:
    """
    æ‹›æŠ•æ ‡åŠ©æ‰‹ Agent
    
    ä½¿ç”¨æ–¹æ³•:
        agent = Agent()
        result = agent.run("æŸ¥æ‰¾è¿‘3å¹´çš„èƒ½æºç±»ä¸šç»©")
        print(result.final_answer)
    """
    
    def __init__(self, max_steps: int = None):
        """
        åˆå§‹åŒ– Agent
        
        å‚æ•°:
            max_steps: æœ€å¤§æ‰§è¡Œæ­¥éª¤æ•°
        """
        self.client = get_llm_client()
        self.max_steps = max_steps or AGENT_MAX_STEPS
    
    def _call_llm(self, prompt: str) -> str:
        """
        è°ƒç”¨ LLM - è°ƒè¯•ç‰ˆæœ¬
        """
        print(f"ğŸ” === LLM è°ƒç”¨å¼€å§‹ ===")
        print(f"ğŸ” ä½¿ç”¨æ¨¡å‹: {REASONING_MODEL}")
        print(f"ğŸ” === LLM è°ƒç”¨åˆ†å‰²çº¿ ===")
        
        try:
            response = self.client.chat.completions.create(
                model=REASONING_MODEL,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=2000,
            )
            
            content = response.choices[0].message.content
            return content
            
        except Exception as e:
            print(f"âŒ LLM è°ƒç”¨å¤±è´¥: {e}")
            print(f"âŒ é”™è¯¯ç±»å‹: {type(e)}")
            raise
    
    def _think(self, context: AgentContext) -> dict:
        """
        æ€è€ƒé˜¶æ®µï¼šåˆ†æä»»åŠ¡ï¼Œå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
        
        å‚æ•°:
            context: Agent ä¸Šä¸‹æ–‡
        è¿”å›:
            è§£æåçš„è¡ŒåŠ¨å†³ç­–
        """
        try:
            # æ„å»ºæç¤ºè¯
            prompt = build_system_prompt(
                task=context.task,
                steps=context.steps,
            )
        except Exception as e:
            print(f"   âŒ æ„å»ºæç¤ºè¯å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
        
        try:
            # è°ƒç”¨ LLM
            response_text = self._call_llm(prompt)
            print(f"   ğŸ“¨ LLM å“åº”é•¿åº¦: {len(response_text)} å­—ç¬¦")
        except Exception as e:
            print(f"   âŒ LLM è°ƒç”¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
        
        try:
            # è§£æå“åº”
            decision = parse_agent_response(response_text)
            return decision
        except Exception as e:
            print(f"   âŒ è§£æå“åº”å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def _execute_tool(self, tool_name: str, tool_params: dict) -> dict:
        """
        æ‰§è¡Œå·¥å…·
        
        å‚æ•°:
            tool_name: å·¥å…·åç§°
            tool_params: å·¥å…·å‚æ•°
        è¿”å›:
            å·¥å…·æ‰§è¡Œç»“æœ
        """
        result = tool_registry.call(tool_name, **(tool_params or {}))
        
        if result.success:
            return {"success": True, "data": result.result}
        else:
            return {"success": False, "error": result.error}
    
    def run(self, task: str) -> AgentContext:
        """
        è¿è¡Œ Agent å®Œæˆä»»åŠ¡
        
        å‚æ•°:
            task: ç”¨æˆ·ä»»åŠ¡/é—®é¢˜
        è¿”å›:
            AgentContext åŒ…å«å®Œæ•´æ‰§è¡Œè¿‡ç¨‹å’Œç»“æœ
        """
        # åˆå§‹åŒ–ä¸Šä¸‹æ–‡
        context = AgentContext(
            task=task,
            max_steps=self.max_steps,
        )
        
        print(f"\n{'='*50}")
        print(f"ğŸš€ Agent å¼€å§‹æ‰§è¡Œä»»åŠ¡")
        print(f"ğŸ“‹ ä»»åŠ¡: {task}")
        print(f"{'='*50}")
        
        # ä¸»å¾ªç¯
        while not context.is_finished() and not context.is_over_limit():
            # 1. æ€è€ƒé˜¶æ®µ
            context.current_state = AgentState.THINKING
            print(f"\nğŸ¤” [Step {context.current_step + 1}] æ€è€ƒä¸­...")
            
            try:
                decision = self._think(context)
            except Exception as e:
                context.add_step(
                    state=AgentState.ERROR,
                    error=f"æ€è€ƒé˜¶æ®µå‡ºé”™: {str(e)}",
                )
                break
            
            thought = decision.get("thought", "")
            action = decision.get("action")
            answer = decision.get("answer")
            
            print(f"   ğŸ’­ æ€è€ƒ: {thought[:100]}..." if len(thought) > 100 else f"   ğŸ’­ æ€è€ƒ: {thought}")
            
            # 2. æ£€æŸ¥æ˜¯å¦æœ‰æœ€ç»ˆç­”æ¡ˆ
            if answer:
                context.add_step(
                    state=AgentState.DONE,
                    thought=thought,
                )
                context.final_answer = answer
                context.current_state = AgentState.DONE
                print(f"   âœ… å¾—å‡ºç­”æ¡ˆ")
                break
            
            # 3. æ‰§è¡Œå·¥å…·
            if action and action.get("tool"):
                tool_name = action["tool"]
                tool_params = action.get("params", {})
                
                context.current_state = AgentState.EXECUTING
                print(f"   ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}")
                print(f"   ğŸ“¥ å‚æ•°: {tool_params}")
                
                try:
                    tool_result = self._execute_tool(tool_name, tool_params)
                except Exception as e:
                    tool_result = {"success": False, "error": str(e)}
                
                # 4. è§‚å¯Ÿç»“æœ
                context.current_state = AgentState.OBSERVING
                
                if tool_result.get("success"):
                    result_data = tool_result.get("data", {})
                    print(f"   ğŸ“¤ ç»“æœ: æˆåŠŸ")
                    
                    context.add_step(
                        state=AgentState.OBSERVING,
                        thought=thought,
                        tool_name=tool_name,
                        tool_params=tool_params,
                        tool_result=result_data,
                    )
                else:
                    error_msg = tool_result.get("error", "æœªçŸ¥é”™è¯¯")
                    print(f"   âŒ ç»“æœ: å¤±è´¥ - {error_msg}")
                    
                    context.add_step(
                        state=AgentState.OBSERVING,
                        thought=thought,
                        tool_name=tool_name,
                        tool_params=tool_params,
                        error=error_msg,
                    )
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ä¹Ÿæ²¡æœ‰ç­”æ¡ˆï¼Œè®°å½•æ€è€ƒæ­¥éª¤
                context.add_step(
                    state=AgentState.THINKING,
                    thought=thought,
                )
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æ­¥éª¤é™åˆ¶
        if context.is_over_limit() and not context.final_answer:
            context.current_state = AgentState.ERROR
            context.final_answer = "æŠ±æ­‰ï¼Œæˆ‘å°è¯•äº†å¤šæ¬¡ä½†æœªèƒ½å®Œæˆä»»åŠ¡ã€‚è¯·å°è¯•ç®€åŒ–é—®é¢˜æˆ–æä¾›æ›´å¤šä¿¡æ¯ã€‚"
            print(f"\nâš ï¸ è¶…è¿‡æœ€å¤§æ­¥éª¤é™åˆ¶ ({self.max_steps})")
        
        print(f"\n{'='*50}")
        print(f"ğŸ Agent æ‰§è¡Œå®Œæˆ")
        print(f"ğŸ“Š æ€»æ­¥éª¤: {context.current_step}")
        print(f"{'='*50}")
        
        return context
    
    def run_stream(self, task: str) -> Generator[dict, None, None]:
        """
        æµå¼è¿è¡Œ Agentï¼ˆç”¨äº SSE æ¨é€ï¼‰
        
        å‚æ•°:
            task: ç”¨æˆ·ä»»åŠ¡/é—®é¢˜
        ç”Ÿæˆ:
            æ‰§è¡Œè¿‡ç¨‹ä¸­çš„äº‹ä»¶
        """
        # åˆå§‹åŒ–ä¸Šä¸‹æ–‡
        context = AgentContext(
            task=task,
            max_steps=self.max_steps,
        )
        
        yield {"event": "start", "data": {"task": task}}
        
        # ä¸»å¾ªç¯
        while not context.is_finished() and not context.is_over_limit():
            # 1. æ€è€ƒé˜¶æ®µ
            context.current_state = AgentState.THINKING
            yield {"event": "status", "data": {"state": "thinking", "step": context.current_step + 1}}
            
            try:
                decision = self._think(context)
            except Exception as e:
                context.add_step(state=AgentState.ERROR, error=str(e))
                yield {"event": "error", "data": {"error": str(e)}}
                break
            
            thought = decision.get("thought", "")
            action = decision.get("action")
            answer = decision.get("answer")
            
            yield {"event": "thinking", "data": {"thought": thought}}
            
            # 2. æ£€æŸ¥æ˜¯å¦æœ‰æœ€ç»ˆç­”æ¡ˆ
            if answer:
                context.add_step(state=AgentState.DONE, thought=thought)
                context.final_answer = answer
                context.current_state = AgentState.DONE
                yield {"event": "answer", "data": {"answer": answer}}
                break
            
            # 3. æ‰§è¡Œå·¥å…·
            if action and action.get("tool"):
                tool_name = action["tool"]
                tool_params = action.get("params", {})
                
                context.current_state = AgentState.EXECUTING
                yield {
                    "event": "tool_call",
                    "data": {"tool": tool_name, "params": tool_params}
                }
                
                try:
                    tool_result = self._execute_tool(tool_name, tool_params)
                except Exception as e:
                    tool_result = {"success": False, "error": str(e)}
                
                # 4. è§‚å¯Ÿç»“æœ
                context.current_state = AgentState.OBSERVING
                
                if tool_result.get("success"):
                    result_data = tool_result.get("data", {})
                    context.add_step(
                        state=AgentState.OBSERVING,
                        thought=thought,
                        tool_name=tool_name,
                        tool_params=tool_params,
                        tool_result=result_data,
                    )
                    yield {
                        "event": "tool_result",
                        "data": {"tool": tool_name, "success": True, "result": result_data}
                    }
                else:
                    error_msg = tool_result.get("error", "æœªçŸ¥é”™è¯¯")
                    context.add_step(
                        state=AgentState.OBSERVING,
                        thought=thought,
                        tool_name=tool_name,
                        tool_params=tool_params,
                        error=error_msg,
                    )
                    yield {
                        "event": "tool_result",
                        "data": {"tool": tool_name, "success": False, "error": error_msg}
                    }
            else:
                context.add_step(state=AgentState.THINKING, thought=thought)
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æ­¥éª¤é™åˆ¶
        if context.is_over_limit() and not context.final_answer:
            context.current_state = AgentState.ERROR
            context.final_answer = "æŠ±æ­‰ï¼Œæˆ‘å°è¯•äº†å¤šæ¬¡ä½†æœªèƒ½å®Œæˆä»»åŠ¡ã€‚"
            yield {"event": "error", "data": {"error": "è¶…è¿‡æœ€å¤§æ­¥éª¤é™åˆ¶"}}
        
        yield {"event": "done", "data": {"total_steps": context.current_step}}

# endregion
# ============================================