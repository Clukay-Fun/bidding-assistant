"""
RAGé—®ç­”ç³»ç»Ÿ
åŠŸèƒ½ï¼šæ£€ç´¢ç›¸å…³æ–‡æ¡£ + LLMç”Ÿæˆç­”æ¡ˆï¼ˆå¸¦å¼•ç”¨ï¼‰
"""

from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI as OpenAIClient
import os
import time

from llama_index.core import Settings, VectorStoreIndex
from llama_index.vector_stores.qdrant import QdrantVectorStore
from llama_index.embeddings.openai import OpenAIEmbedding
from qdrant_client import QdrantClient

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ============================================
# region é…ç½®åŒºåŸŸ
# ============================================

# ç¡…åŸºæµåŠ¨APIé…ç½®
SILICONFLOW_API_KEY = os.getenv("SILICONFLOW_API_KEY")
SILICONFLOW_BASE_URL = "https://api.siliconflow.cn/v1"

# æ¨¡å‹é…ç½®
EMBEDDING_MODEL = "BAAI/bge-m3"
LLM_MODEL = "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B"
RERANK_MODEL = "BAAI/bge-reranker-v2-m3"

# Qdranté…ç½®
QDRANT_PATH = "./qdrant_data"
COLLECTION_NAME = "bidding_docs"

# endregion
# ============================================


# ============================================
# region å®¢æˆ·ç«¯åˆå§‹åŒ–
# ============================================

def get_llm_client() -> OpenAIClient:
    """è·å–LLMå®¢æˆ·ç«¯"""
    return OpenAIClient(
        api_key=SILICONFLOW_API_KEY,
        base_url=SILICONFLOW_BASE_URL
    )


def get_rerank_client() -> OpenAIClient:
    """è·å–Rerankå®¢æˆ·ç«¯ï¼ˆç¡…åŸºæµåŠ¨ï¼‰"""
    return OpenAIClient(
        api_key=SILICONFLOW_API_KEY,
        base_url=SILICONFLOW_BASE_URL
    )


def init_embedding():
    """åˆå§‹åŒ–Embeddingæ¨¡å‹"""
    embed_model = OpenAIEmbedding(
        api_key=SILICONFLOW_API_KEY,
        api_base=SILICONFLOW_BASE_URL,
        model_name=EMBEDDING_MODEL,
        embed_batch_size=32,
    )
    Settings.embed_model = embed_model
    print(f"âœ… Embedding: {EMBEDDING_MODEL}")


def load_index() -> VectorStoreIndex:
    """åŠ è½½å·²æœ‰çš„å‘é‡ç´¢å¼•"""
    print(f"ğŸ“‚ åŠ è½½ç´¢å¼•: {COLLECTION_NAME}")
    
    client = QdrantClient(path=QDRANT_PATH)
    vector_store = QdrantVectorStore(
        client=client,
        collection_name=COLLECTION_NAME,
    )
    
    index = VectorStoreIndex.from_vector_store(vector_store)
    print(f"âœ… ç´¢å¼•åŠ è½½å®Œæˆ")
    return index

# endregion
# ============================================


# ============================================
# region Reranké‡æ’åº
# ============================================

def rerank_nodes(query: str, nodes: list, top_n: int = 3) -> list:
    """
    ä½¿ç”¨ç¡…åŸºæµåŠ¨çš„Rerank APIå¯¹ç»“æœé‡æ’åº
    
    å‚æ•°:
        query: æŸ¥è¯¢æ–‡æœ¬
        nodes: æ£€ç´¢åˆ°çš„èŠ‚ç‚¹åˆ—è¡¨
        top_n: ä¿ç•™å‰Nä¸ªç»“æœ
    
    è¿”å›:
        é‡æ’åºåçš„èŠ‚ç‚¹åˆ—è¡¨
    """
    if not nodes:
        return nodes
    
    try:
        import httpx
        
        # å‡†å¤‡æ–‡æ¡£åˆ—è¡¨
        documents = [node.text for node in nodes]
        
        # è°ƒç”¨Rerank API
        response = httpx.post(
            f"{SILICONFLOW_BASE_URL}/rerank",
            headers={
                "Authorization": f"Bearer {SILICONFLOW_API_KEY}",
                "Content-Type": "application/json"
            },
            json={
                "model": RERANK_MODEL,
                "query": query,
                "documents": documents,
                "top_n": top_n
            },
            timeout=30.0
        )
        
        if response.status_code == 200:
            result = response.json()
            
            # æŒ‰ç…§é‡æ’åºç»“æœé‡æ–°æ’åˆ—nodes
            reranked_nodes = []
            for item in result.get("results", []):
                idx = item["index"]
                if idx < len(nodes):
                    # æ›´æ–°åˆ†æ•°
                    nodes[idx].score = item["relevance_score"]
                    reranked_nodes.append(nodes[idx])
            
            print(f"   ğŸ”„ Rerankå®Œæˆï¼Œä¿ç•™ {len(reranked_nodes)} ä¸ªç»“æœ")
            return reranked_nodes
        else:
            print(f"   âš ï¸ Rerank APIè¿”å›é”™è¯¯: {response.status_code}")
            return nodes[:top_n]
            
    except Exception as e:
        print(f"   âš ï¸ Rerankå¤±è´¥: {e}")
        return nodes[:top_n]

# endregion
# ============================================


# ============================================
# region LLMè°ƒç”¨
# ============================================

QA_PROMPT_TEMPLATE = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ‹›æŠ•æ ‡æ–‡æ¡£åˆ†æåŠ©æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

## è¦æ±‚
1. åªæ ¹æ®æä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯
2. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®å‘ŠçŸ¥
3. å›ç­”è¦å‡†ç¡®ã€ç®€æ´ã€ä¸“ä¸š
4. åœ¨å›ç­”æœ«å°¾æ ‡æ³¨ä¿¡æ¯æ¥æºï¼ˆä½¿ç”¨æ–‡æ¡£è·¯å¾„ï¼‰

## æ£€ç´¢åˆ°çš„æ–‡æ¡£å†…å®¹
{context}

## ç”¨æˆ·é—®é¢˜
{question}

## å›ç­”
"""


def call_llm(prompt: str) -> str:
    """è°ƒç”¨LLMç”Ÿæˆå›ç­”"""
    client = get_llm_client()
    
    response = client.chat.completions.create(
        model=LLM_MODEL,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ‹›æŠ•æ ‡æ–‡æ¡£åˆ†æåŠ©æ‰‹ã€‚"},
            {"role": "user", "content": prompt}
        ],
        temperature=0.1,
        max_tokens=2000
    )
    
    return response.choices[0].message.content

# endregion
# ============================================


# ============================================
# region RAGé—®ç­”
# ============================================

def query_with_sources(
    index: VectorStoreIndex,
    question: str,
    top_k: int = 5,
    use_rerank: bool = True,
    rerank_top_n: int = 3
) -> dict:
    """
    å¸¦å¼•ç”¨æ¥æºçš„RAGé—®ç­”
    """
    start_time = time.time()
    
    # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
    retriever = index.as_retriever(similarity_top_k=top_k)
    nodes = retriever.retrieve(question)
    print(f"   ğŸ“„ æ£€ç´¢åˆ° {len(nodes)} ä¸ªç›¸å…³æ–‡æ¡£")
    
    # 2. é‡æ’åº
    if use_rerank and len(nodes) > 0:
        nodes = rerank_nodes(question, nodes, top_n=rerank_top_n)
    
    # 3. æ„å»ºä¸Šä¸‹æ–‡
    context_parts = []
    sources = []
    
    for i, node in enumerate(nodes, 1):
        title = node.metadata.get("title", "æœªçŸ¥")
        path = node.metadata.get("path", "æœªçŸ¥")
        content = node.text
        
        context_parts.append(f"ã€æ–‡æ¡£{i}ã€‘\næ ‡é¢˜: {title}\nè·¯å¾„: {path}\nå†…å®¹: {content}\n")
        sources.append({
            "title": title,
            "path": path,
            "content": content[:200] + "..." if len(content) > 200 else content,
            "score": node.score
        })
    
    context = "\n".join(context_parts)
    
    # 4. è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆ
    prompt = QA_PROMPT_TEMPLATE.format(context=context, question=question)
    answer = call_llm(prompt)
    
    elapsed = time.time() - start_time
    
    return {
        "answer": answer,
        "sources": sources,
        "time": elapsed
    }

# endregion
# ============================================


# ============================================
# region äº¤äº’å¼é—®ç­”
# ============================================

def interactive_qa(index: VectorStoreIndex):
    """äº¤äº’å¼é—®ç­”"""
    print("\n" + "="*50)
    print("ğŸ’¬ æ‹›æŠ•æ ‡æ–‡æ¡£é—®ç­”ç³»ç»Ÿ")
    print("="*50)
    print("è¾“å…¥é—®é¢˜è¿›è¡ŒæŸ¥è¯¢ï¼Œè¾“å…¥ 'quit' æˆ– 'q' é€€å‡º\n")
    
    while True:
        question = input("ğŸ™‹ ä½ çš„é—®é¢˜: ").strip()
        
        if question.lower() in ['quit', 'q', 'é€€å‡º']:
            print("ğŸ‘‹ å†è§ï¼")
            break
        
        if not question:
            continue
        
        print(f"\nğŸ” æ­£åœ¨æŸ¥è¯¢...")
        
        try:
            result = query_with_sources(index, question)
            
            print(f"\n{'='*50}")
            print(f"ğŸ“ å›ç­”ï¼š")
            print(f"{'='*50}")
            print(result["answer"])
            
            print(f"\n{'='*50}")
            print(f"ğŸ“š å¼•ç”¨æ¥æºï¼ˆå…±{len(result['sources'])}æ¡ï¼‰ï¼š")
            print(f"{'='*50}")
            for i, source in enumerate(result["sources"], 1):
                print(f"\n[{i}] {source['title']}")
                print(f"    è·¯å¾„: {source['path']}")
                print(f"    ç›¸ä¼¼åº¦: {source['score']:.4f}")
            
            print(f"\nâ±ï¸ è€—æ—¶: {result['time']:.2f} ç§’\n")
            
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å‡ºé”™: {e}\n")

# endregion
# ============================================


# ============================================
# region ä¸»å‡½æ•°
# ============================================

def main():
    print("\n" + "="*50)
    print("ğŸš€ RAGé—®ç­”ç³»ç»Ÿå¯åŠ¨")
    print("="*50 + "\n")
    
    # åˆå§‹åŒ–
    init_embedding()
    print(f"âœ… LLM: {LLM_MODEL}")
    print(f"âœ… Rerank: {RERANK_MODEL}")
    
    # åŠ è½½ç´¢å¼•
    index = load_index()
    
    # å¯åŠ¨äº¤äº’å¼é—®ç­”
    interactive_qa(index)


if __name__ == "__main__":
    main()

# endregion
# ============================================