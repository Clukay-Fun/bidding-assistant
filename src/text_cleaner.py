"""
æ–‡æœ¬æ¸…æ´—æ¨¡å—
åŠŸèƒ½ï¼šè¿‡æ»¤æ°´å°ã€æ¸…ç†OCRç»“æœ
"""

from collections import Counter
from rapidfuzz import fuzz


# ============================================
# region æ°´å°è¿‡æ»¤
# ============================================

def filter_watermarks(
    ocr_results: list,
    freq_threshold_ratio: float = 0.5,
    min_threshold: int = 3,
    similarity_threshold: float = 70.0,
    max_watermark_len: int = 12
) -> list:
    """
    è¿‡æ»¤OCRç»“æœä¸­çš„æ°´å°æ–‡æœ¬
    
    å‚æ•°:
        ocr_results: OCRç»“æœåˆ—è¡¨ï¼Œæ ¼å¼ä¸º [{"page": 1, "content": [{"text": "..."}]}]
        freq_threshold_ratio: é¢‘ç‡é˜ˆå€¼æ¯”ä¾‹ï¼ˆç›¸å¯¹äºæ€»é¡µæ•°ï¼‰
        min_threshold: æœ€å°é¢‘ç‡é˜ˆå€¼
        similarity_threshold: æ¨¡ç³ŠåŒ¹é…ç›¸ä¼¼åº¦é˜ˆå€¼
        max_watermark_len: æ°´å°æœ€å¤§é•¿åº¦
    
    è¿”å›:
        è¿‡æ»¤åçš„OCRç»“æœ
    """
    # ç»Ÿè®¡æ‰€æœ‰æ–‡æœ¬çš„å‡ºç°é¢‘ç‡
    text_counter = Counter()
    total_pages = len(ocr_results)
    
    for page in ocr_results:
        for item in page.get("content", []):
            text = item.get("text", "").strip()
            if text and len(text) <= max_watermark_len:
                text_counter[text] += 1
    
    # è®¡ç®—é¢‘ç‡é˜ˆå€¼
    freq_threshold = max(total_pages * freq_threshold_ratio, min_threshold)
    
    # ç­›é€‰å€™é€‰æ°´å°
    candidate_watermarks = {
        text for text, count in text_counter.items()
        if count >= freq_threshold
    }
    
    print(f"ğŸ“Š æ€»é¡µæ•°: {total_pages}, é¢‘ç‡é˜ˆå€¼: {freq_threshold}")
    print(f"ğŸ“‹ å‘ç° {len(candidate_watermarks)} ä¸ªå€™é€‰æ°´å°:")
    for wm in candidate_watermarks:
        print(f"   - \"{wm}\" (å‡ºç° {text_counter[wm]} æ¬¡)")
    
    # å®šä¹‰æ°´å°åˆ¤æ–­å‡½æ•°
    def is_watermark(text: str) -> bool:
        if not text or len(text) > max_watermark_len:
            return False
        
        # ç²¾ç¡®åŒ¹é…
        if text in candidate_watermarks:
            return True
        
        # æ¨¡ç³ŠåŒ¹é…
        for wm in candidate_watermarks:
            if fuzz.ratio(text, wm) >= similarity_threshold:
                return True
        
        return False
    
    # è¿‡æ»¤æ°´å°
    filtered_results = []
    watermark_count = 0
    
    for page in ocr_results:
        filtered_content = []
        
        for item in page.get("content", []):
            text = item.get("text", "").strip()
            
            if is_watermark(text):
                watermark_count += 1
            else:
                # æ›¿æ¢å¯èƒ½ç ´åMarkdownçš„å­—ç¬¦
                cleaned_text = text.replace("|", "ï½œ")
                filtered_content.append({
                    "text": cleaned_text,
                    "confidence": item.get("confidence", 0)
                })
        
        filtered_results.append({
            "page": page["page"],
            "content": filtered_content
        })
    
    print(f"ğŸ—‘ï¸ å…±è¿‡æ»¤ {watermark_count} æ¡æ°´å°æ–‡æœ¬")
    
    return filtered_results

# endregion
# ============================================


if __name__ == "__main__":
    # æµ‹è¯•
    test_data = [
        {"page": 1, "content": [{"text": "æ­£æ–‡å†…å®¹"}, {"text": "ä»…é™äºæŠ•æ ‡ä½¿ç”¨"}]},
        {"page": 2, "content": [{"text": "æ›´å¤šå†…å®¹"}, {"text": "ä»…é™äºæŠ•æ ‡ä½¿ç”¨"}]},
    ]
    
    result = filter_watermarks(test_data)
    print("\nè¿‡æ»¤åç»“æœ:")
    for page in result:
        print(f"ç¬¬{page['page']}é¡µ: {[item['text'] for item in page['content']]}")
